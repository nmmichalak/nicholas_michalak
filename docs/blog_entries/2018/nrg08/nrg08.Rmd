---
title: "Plotting Adjusted Associations in R"
output: 
  html_document: 
    theme: readable
---

# What is a correlation?
> A correlation quantifies the linear association between two variables. From one perspective, a correlation has two parts: one part quantifies the association, and the other part sets the scale of that association.  

> The first part--the covariance, also the correlation numerator--equates to a sort of "average sum of squares" of two variables:  

## $cov_{(X, Y)} = \frac{\sum(X - \bar X)(Y - \bar Y)}{N - 1}$  

> It could be easier to interpret the covariance as an "average of the X-Y matches": X scores above the X mean multipled by Y scores below the Y mean will be negative, and X scores above the X mean multipled by Y scores above the Y mean will be positive.  

> The second part--the product of the standard deviations, also the correlation denominator--restricts the association to values from -1.00 to 1.00.

## $\sqrt{var_X  var_Y} = \sqrt{\frac{\sum(X - \bar X)^2}{N - 1} \frac{\sum(Y - \bar Y)^2}{N - 1}}$  

> Divide the numerator by the denominator and you get a sort of "ratio of the sum of squares", the correlation:

## $r_{XY} = \frac{\frac{\sum(X - \bar X)(Y - \bar Y)}{N - 1}}{\sqrt{\frac{\sum(X - \bar X)^2}{N - 1} \frac{\sum(Y - \bar Y)^2}{N - 1}}} = \frac{cov_{(X, Y)}}{\sqrt{var_X  var_Y}}$  

> Square this "standardized covariance" for an estimate of the proportion of variance of Y that can be accounted for by a linear function of X, $r^2_{XY}$.

# What does it mean to "adjust" a correlation?
> An adjusted correlation refers to the (square root of the) change in a regression model's $r^2$ after adding a single predictor to the model: $r^2_{full} - r^2_{reduced}$. This change quantifies that additional predictor's "unique" contribution to observed variance explained. Put another way, this value quantifies observed variance in Y explained by a linear function in X after removing variance shared between X and the other predictors in the model.

# Model and Conceptual Assumptions for Linear Regression
> * **Correct functional form.** Your model variables share linear relationships.  
> * **No omitted influences.** This one is hard: Your model accounts for all relevant influences on the variables included. All models are wrong, but how wrong is yours?  
> * **Accurate measurement.** Your measurements are valid and reliable. Note that unreliable measures can't be valid, and reliable measures don't necessairly measure just one construct or even your construct.  
> * **Well-behaved residuals.** Residuals (i.e., prediction errors) aren't correlated with predictor variables or eachother, and residuals have constant variance across values of your predictor variables.  

## Libraries

```{r, warning = FALSE, message = FALSE}

# library("tidyverse")
# library("knitr")
# library("effects")
# library("psych")
# library("candisc")

library(tidyverse)
library(knitr)
library(effects)
library(psych)
library(candisc)

# select from dplyr
select <- dplyr::select
recode <- dplyr::recode

```

## Load data
> From `help("HSB")`: "The High School and Beyond Project was a longitudinal study of students in the U.S. carried out in 1980 by the National Center for Education Statistics. Data were collected from 58,270 high school students (28,240 seniors and 30,030 sophomores) and 1,015 secondary schools. The HSB data frame is sample of 600 observations, of unknown characteristics, originally taken from Tatsuoka (1988)."

```{r}

HSB <- as_tibble(HSB)

# print a random subset of rows from the dataset
HSB %>% sample_n(size = 15) %>% kable()

```

# Do students who score higher on a standardized math test tend to score higher on a standardized science test?

## scatterplot
> `alpha` below refers to the points' transparency (0.5 = 50%), `lm` refers to linear model and `se` refers to standard error bands

```{r}

HSB %>% 
  ggplot(mapping = aes(x = math, y = sci)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "red")

```

## center the standardized math scores
> If the standardized math scores are centered around their mean (i.e., 0 = mean), then we can interpret the regression intercept--x = 0 when the regression line crosses the y-axis--as the grand mean standardized science score.

```{r}

HSB <- HSB %>% mutate(math_c = math - mean(math, na.rm = TRUE))

```

## fit model

```{r}

scimath1 <- lm(sci ~ math_c, data = HSB)

```

## summarize model

```{r}

summary(scimath1)

# print the standardized science score descriptive statistics
HSB %>% pull(sci) %>% describe()

```

## Interpretation
> On average, students scored 51.76 points (*SD* = 9.71 points) on the standardized science test. However, for every one more point students scored on the standardized math test, they scored 0.67 more points (*SE* = 0.03) on the standardized science test, *t*(598) = 20.89, *p* < .001.

# If we account for the fact that students who score higher on a standardized math test also tend to score higher on standardized reading test, do students who score higher on the standardized math test **still** tend to score higher on the standardized science test?

## center the standardized reading scores
> same explanation as above--because the regression line crosses the y-axis when the predictors' axses = 0, transforming those predictors so that 0 reflects their means allows us to interpret the regression intercept as the grand mean standardized science score.

```{r}

HSB <- HSB %>% mutate(read_c = read - mean(read, na.rm = TRUE))

```

## fit model

```{r}

scimath2 <- lm(sci ~ math_c + read_c, data = HSB)

```

## summarize model

```{r}

summary(scimath2)

```

## compare models

```{r}

summary(scimath2)$adj.r.squared - summary(scimath1)$adj.r.squared
anova(scimath1, scimath2)

```

## save both model predictions in tables
> below, I use the `effect()` function to estimate standardized science scores at unique range of values of standardized math scores (partialling out the linear effect of standardized reading scores in scimath2). then I transform the result into a `tibble` `data.frame`, which includes fitted values, predictor values, standard errors of the predictions, and upper and lower confidence values for the predictions. I can use this table to create a regression line and confidence bands in a plot.

```{r}

scimath_predtable1 <- effect(term = "math_c", mod = scimath1) %>% as_tibble()
scimath_predtable2 <- effect(term = "math_c", mod = scimath2) %>% as_tibble()

```

## plot adjusted relationship

```{r}

HSB %>% 
  ggplot(mapping = aes(x = math_c, y = sci)) +
  geom_point(alpha = 0.5) +
  geom_line(data = scimath_predtable1, mapping = aes(x = math_c, y = fit), color = "red") +
  geom_line(data = scimath_predtable2, mapping = aes(x = math_c, y = fit), color = "blue") +
  geom_ribbon(data = scimath_predtable2, mapping = aes(x = math_c, y = fit, ymin = lower, ymax = upper), fill = "blue", alpha = 0.25) +
  labs(x = "Standardized math score (grand mean centered)", y = "Standardized science score")

```

## Interpretation
> After partialling out variance shared between standardized math and reading scores, for every one more point students scored on the standardized math test, they scored 0.35 more points (*SE* = 0.04) on the standardized science test, *t*(597) = 12.21, *p* < .001. Importantly, the model explained 53.60% of the observed variance in standardized science scores, an 11.50% improvement over the model (due to reading scores) that included only standardized math scores.

# Resources
> * Cohen, J., Cohen, P., West, S. G., & Aiken, L. S. (2003). *Applied multiple regression/correlation analysis for the behavioral sciences*. New York, NY: Routledge.
> * Gonzalez, R. (December, 2016). *Lecture Notes #8: Advanced Regression Techniques I* Retreived from [http://www-personal.umich.edu/~gonzo/coursenotes/file8.pdf](http://www-personal.umich.edu/~gonzo/coursenotes/file8.pdf) on June 28th, 2018.
> * MacKinnon, D. P. (2008). *Introduction to statistical mediation analysis.* New York, NY: Lawrence Erlbaum Associates.

# General word of caution
> Above, I listed resources prepared by experts on these and related topics. Although I generally do my best to write accurate posts, don't assume my posts are 100% accurate or that they apply to your data or research questions. Trust statistics and methodology experts, not blog posts.